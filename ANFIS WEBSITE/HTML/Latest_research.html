<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Latest Research in Cardiology</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background: url('anatomy.png') no-repeat center center fixed;
            background-size: cover;
        }
        .container {
            max-width: 1200px;
            margin: 20px auto;
            padding: 20px;
            background: rgba(255, 255, 255, 0.8);
            box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);
            border-radius: 10px;
        }
        .header {
            text-align: center;
            padding: 20px;
        }
        .header h1 {
            color: #d9534f;
        }
        .content {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
        }
        .column {
            flex: 1;
            min-width: 300px;
            background: #fff;
            padding: 15px;
            border-radius: 10px;
        }
        .image {
            width: 100%;
            height: auto;
            border-radius: 10px;
        }
        .footer {
            text-align: center;
            padding: 10px;
            background: #d9534f;
            color: white;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Latest Research in Cardiology</h1>
            <p></p>
        </div>
        <div class="content">
            <div class="column">
                <h2>The year in cardiovascular medicine 2025: Ischaemic heart disease </h2>
                
                <p><b>Summary</b></p>
                <p>Ischaemic heart disease remains the leading cause of death globally, according to the World Health Organization. Here, we summarize the top 10 papers in 2024 that we think may help facilitate better classification, detection, risk stratification, and, ultimately, treatment of patients with ischaemic heart disease (Graphical Abstract).</p>
                <p><b>Acute and non-acute myocardial ischaemic syndromes: a new nomenclature to harmonize international guidelines</b></p>
                <p>For chronic stable manifestations of myocardial ischaemia, various classifications have emerged over time, often with conflicting terminology across international professional societies—e.g. ‘stable coronary artery disease’ (CAD), ‘stable ischaemic heart disease’, ‘chronic coronary syndromes’, and, more recently, ‘chronic coronary disease’. An unintended consequence of these competing classifications is perpetuation of the more restrictive terms ‘coronary’ and ‘disease’, often connoting a singular obstructive CAD mechanism. A proposed new binary classification includes ‘acute myocardial ischaemic syndromes’ and ‘non-acute myocardial ischaemic syndromes’, which comprises both obstructive epicardial and non-obstructive pathogenetic mechanisms, including microvascular dysfunction, vasospastic disorders, and other non-coronary causes.1 The new nomenclature encompasses the many clinical presentations and pathogenetic ‘phenotypes’ of angina and myocardial ischaemia beyond epicardial coronary obstruction and better aligns, unifies, and harmonizes different pathophysiologic causes of angina, ischaemia, and myocardial infarction (MI). This should, in turn, enable more refined therapeutic approaches, targeted at the multiple underlying pathobiological precipitants.</p>
                
                <p><b>Beta-blockers post-myocardial infarction</b></p>
                <p>Early trials, predominantly in the 1980s, showed that beta-blockers improved cardiovascular outcomes in patients with MI. Beta-blockers became the standard-of-care treatment for patients post-MI and, once started, are often continued lifelong. Two landmark trials turn this practice on its head, by showing that in the current era of routine primary percutaneous coronary intervention (PCI) for ST-segment elevation MI, high-intensity statins, and renin–angiotensin–aldosterone system antagonists, there is no compelling support for treating MI patients without significantly impaired left ventricular (LV) systolic function with long-term beta-blockade. </p>
                <p>In the open-label REDUCE-AMI trial, 5020 patients with MI and LV ejection fraction ≥ 50% were randomized to either long-term treatment with a beta-blocker (metoprolol or bisoprolol) or no beta-blocker.At a median follow-up of 3.5 years, the primary endpoint of the composite of all-cause death or new MI was similar with and without beta-blockers [7.9% vs. 8.3%, 95% confidence interval (CI) 0.79–1.16; P = .64]. Likewise, there was no difference in the secondary endpoints of death, cardiovascular death, MI, or hospitalization for atrial fibrillation or heart failure.</p>
                <p>In the open-label ABYSS trial, 3698 patients with prior MI (average 2.9 years earlier) and LV ejection fraction ≥ 40%, who had been stable without recent cardiovascular events, were randomly assigned to interruption or continuation of beta-blocker treatment.At a median follow-up of 3 years, beta-blocker interruption was non-inferior to continuation, for the composite of death, MI, stroke, or cardiovascular hospitalization (23.8% vs. 21.1%, 95% CI 1.01–1.33; Pnon-inferiority = .44) and beta-blockers did not improve quality of life.</p>
                <p>Thus, while noting the limitations of open-label studies, unless patients have overt heart failure or significantly impaired LV function, there would appear to be no significant benefit to beta-blockers beyond the acute MI hospitalization. The historical practice of long-term beta-blocker use post-MI in patients without significant LV impairment should be reconsidered.</p>
                
                <p><b>SGLT2 inhibitor post-myocardial infarction</b></p>
                <p>The benefit of SGLT2 inhibitors in improving cardiovascular outcomes of patients with established heart failure is well established. The EMPACT-MI trial, however, aimed to assess whether empagliflozin could improve the outcome of acute MI patients who were at risk of heart failure, based on new LV ejection fraction < 45% or signs or symptoms of congestion necessitating treatment during the index hospitalization.4 A total of 3260 patients with MI were randomized within 14 days of admission, to empagliflozin 10 mg daily or placebo, in addition to standard care. At a mean follow-up of 18 months, empagliflozin failed to improve the primary endpoint of the composite of hospitalization for heart failure or all-cause death, compared with placebo (8.2% vs. 9.1%; 95% CI 0.76–1.06; P = .21).</p>
                
                <p><b>Stenting of non-flow-limiting vulnerable plaques</b></p>
                <p>The PREVENT trial evaluated the effect of preventive stenting of high-risk vulnerable plaques in patients with non-flow-limiting (fractional flow reserve > 0.8) coronary stenoses.5 At 2-year follow-up, there were significantly fewer cardiovascular events in PCI-treated patients, driven largely by a reduction in ischemia-driven target-vessel MI, target-vessel revascularizations, and hospitalizations for unstable/progressive angina, with no effect on cardiovascular mortality. Open-label design confers a serious limitation for outcomes interpretation, particularly when prior knowledge of treatment assignment is present (ascertainment bias). In addition, dual platelet therapy use was significantly higher in the PCI group at 2 years, which may have reduced ischaemic events and contributed to more favourable outcome in this arm. The positive predictive value of the intracoronary imaging modalities used is also likely insufficient for the identification of plaques that would benefit from pre-emptive PCI. Given the very low, non-significant differences in cardiovascular death and MI between the groups, while intriguing, these data should be considered hypothesis generating and cannot justify widespread adoption of prophylactic PCI for ‘vulnerable plaques’.</p>
                
                <p><b>Coronary sinus reducer for refractory angina</b></p>
                <p>The ORBITA-COSMIC is the second randomized, double-blind, sham-controlled trial evaluating coronary sinus reducer (CSR) technology in patients (n = 51) with refractory angina secondary to advanced CAD.6 While CSR failed to improve transmural myocardial perfusion of ischaemic segments on stress perfusion MRI, it reduced the frequency of self-reported angina episodes compared with sham [odds ratio (OR) 1.40, 95% CI 1.08–1.83; probability of benefit = 99.4%]. These results lend support to carefully considered use of CSR to treat refractory angina in appropriately selected patients.</p>

                <p><b>Use of quantitative computed tomography angiography to enhance risk prediction and treatment planning in patients with coronary disease</b></p>
                <p>Inflammation is a driver of coronary atheroma progression and major adverse cardiovascular events (MACE), but beyond using non-specific markers such as C-reactive protein, there are no easy ways to assess this. The recent ORFAN study investigated whether the addition of fat attenuation index (FAI), a radiomic biomarker of coronary inflammation derived from standard coronary computed tomography angiography (CCTA), and an artificial intelligence modelled risk score (AI-Risk score) could improve clinical risk prediction, over and above clinical risk factors (QRISK3) and coronary stenosis burden (CAD-RADS 2.0).7 In this population (n = 40 091), of whom 81% had non-obstructive CAD, the event rate was double in patients with non-obstructive compared with those with obstructive CAD. Elevated FAI significantly predicted increased cardiac mortality and MACE, with hazard increasing with the number of coronary arteries exhibiting elevated FAI. With increasing CCTA use, ORFAN indicates the potential for radiomic inflammatory biomarkers to improve risk stratification, particularly in patients with non-obstructive CAD, which could inform additional use of lipid-lowering or anti-inflammatory therapies.</p>
                <p>Atherosclerosis imaging–quantitative computed tomography (AI-QCT) to quantify plaque volume, composition, and distribution was performed in a post hoc analysis of the ISCHEMIA trial8 in 3711 patients with analyzable CCTA data to assess the incremental predictive value of plaque quantification over traditional risk factors, ejection fraction, prior CAD, and number of diseased vessels, for the composite primary outcome of cardiovascular death or MI, during a median 3.3-year follow-up. Total plaque volume was the most strongly associated AI-QCT variable for the primary outcome, although the model’s predictive value at 6 months, 2 years, and 4 years was modest beyond clinical risk factors alone. The AI-QCT showed that the number of diseased vessels and atherosclerotic burden were independently associated with increased risk of cardiovascular events, while coronary lumen area was inversely associated with risk. Although total plaque volume provided modest improvement in discrimination and some incremental prognostic value when added to clinical characteristics during a relatively short follow-up period, these findings nevertheless support the use of CCTA to enhance risk prediction in patients with CAD.</p>
                <p>The quality of CCTA technology is of sufficient quality nowadays to challenge the need for conventional invasive coronary angiography (ICA) for planning revascularization. In a small study of 114 patients with left mainstem and multivessel CAD selected for surgical revascularization based on prior ICA, investigators of the FAST-TRACK CABG study blindly evaluated the feasibility and efficacy of planning and performing surgical revascularization solely using anatomical and physiological (FFRCT) data derived non-invasively from a state-of-the-art single heartbeat CCTA acquisition.9 There was excellent concordance between CCTA and ICA to guide surgical revascularization (99.1%) and excellent graft patency at 30 days (92.6%). In the future, CCTA may enable completely non-invasive anatomical and functional assessment to guide surgical revascularization.</p>

                <p><b>A possible revival for the exercise ECG</b></p>
                <p>Exercise ECG stress testing for diagnosing myocardial ischaemia has been declining, due to limited sensitivity and specificity, and the use of ICA as the reference standard. In an exploratory, blinded study, 32/102 patients with angina and non-obstructive coronary arteries (ANOCA) had an ischaemic exercise ECG.10 All these patients had invasive evidence of coronary microvascular dysfunction (CMD), whereas among those with a non-ischaemic exercise ECG, only 66% had evidence of CMD. The strongest predictor of an abnormal exercise ECG was impaired endothelium-dependent blood flow response to acetylcholine. Referenced against endothelium-dependent and endothelium-independent coronary physiology metrics, the false positive rate for an ischaemic exercise ECG was 0. This small study indicates a possible ongoing use for the humble treadmill test in patients with ANOCA but requires validation in a larger prospective study.</p>

                
            </div>
            <div class="column">
                <h2>Cardiovascular disease diagnosis: a holistic approach using the integration of machine learning and deep learning models</h2>
                
                <p><b>Introduction</b></p>
                <p>Nowadays massive amounts of data are generated in the healthcare industry and individuals facing these types of data have realized that there is a significant gap between their collection and interpretation. In today's data-driven era, the intersection of healthcare and artificial intelligence has paved the way for transformative advancements in healthcare. In this context, machine learning algorithms have emerged as powerful tools capable of analyzing vast amounts of patient data with unprecedented speed and precision. By harnessing the potential of machine learning, healthcare providers can leverage complex patterns within diverse datasets to develop predictive models for disease diagnosis. These models can identify subtle indicators and risk factors that may elude traditional diagnostic methods, empowering healthcare providers to take proactive measures and customize individualized treatment plans for patients.</p>
                <p>The application of machine learning has provided a new approach to predicting cardiovascular diseases. Consequently, various machine learning methods have been used to recognize and extract useful information from clinical datasets with minimal user input and effort. However, the emergence of deep learning has revolutionized cardiovascular disease prediction by offering distinct advantages over traditional machine learning approaches. Deep learning algorithms, such as neural networks, excel in processing vast amounts of complex data, capturing intricate patterns, and extracting high-level features from raw inputs. In the context of cardiovascular disease prediction, the inherent ability of deep learning models to automatically learn hierarchical representations of data enables them to uncover subtle relationships and dependencies that may not be apparent to conventional machine learning algorithms.</p>

                <p><b>Related work</b></p>
                <p>Using machine learning and deep learning for cardiovascular disease prediction is crucial as it can enhance accuracy in identifying risk factors, enable early detection of potential issues, personalize treatment plans, and ultimately improve patient outcomes through proactive healthcare interventions. Accordingly, numerous have been conducted to investigate and find the appropriate technique for predicting heart disease. While the focus of this paper is to propose a model based on the combination of machine learning and deep learning for cardiovascular prediction, studies conducted in this era are briefly introduced in the following.</p>
                <p>In a similar research direction, Subanya & Rajalaxmi utilized the SVM classification technique along with the Swarm intelligence-based Artificial Bee Colony (ABC) algorithm to find optimal features, resulting in an accuracy of 86.76%. Additionally, Mokeddem et al. utilized the genetic algorithm alongside Naïve Bayes and SVM for classification, yielding accuracies of 85.50% and 83.82%, respectively. Khanna et al.performed a comparative study of classification methods (logistic regression, SVM, and neural networks) to forecast the prevalence of heart disease, determining that logistic regression achieved the best performance with a classification accuracy of 84.80%.</p>

                <p><b>Proposed model</b></p>
                <p>Machine learning and deep learning both offer valuable tools for cardiovascular disease prediction, each with its own set of benefits. Notably, machine learning excels in interpretability, allowing for insights into factors influencing predictions. On the other hand, deep learning can automatically learn intricate patterns in raw data, potentially capturing complex relationships that may be missed by traditional machine learning methods. While each of them has its own benefits and pitfalls, using combinational models for cardiovascular disease prediction offers a significant advantage by harnessing the collective power of diverse predictive models to improve the accuracy and robustness via capturing complex relationships within the data. In this regard, the proposed model leverages the combination of CNN and LSTM from deep learning and KNN and XGB from machine learning as the base classifiers for cardiovascular disease classification.</p>
                <p>The output classes are defined by each classifier, majority voting is then used as an ensemble learner to predict the final output class.Noteworthy, the reason behind choosing each of these classifiers refers to their unique structure while CNN can automatically extract relevant features from the input, effectively capturing key aspects of the data that are important for classification. Moreover, LSTM has the inherent ability to extract relevant features and representations from sequential data without the need for explicit feature engineering. The combination of CNN and LSTM networks allows the model to capture complex relationships and patterns within the clinical data, potentially enabling it to discern intricate dependencies and interactions between different clinical variables, ultimately aiding in accurate disease classification. On the other hand, KNN is effective in capturing local patterns within the feature space. In the context of clinical data, where characteristics of patients and their health profiles can exhibit local patterns, KNN can be suitable for identifying similarities between patients based on their clinical attributes, potentially aiding in patient classification.</p>

                <p><b>Experiments and results</b></p>
                <p>To take advantage of the processing power of the graphics processor, all instructions were implemented using Google Colab based on Python 3.10 as the programming language. The hardware infrastructure for running the proposed model was a system with an Intel Core i5 processor, 8 GB RAM, and an Ubuntu distribution as the operating system.Notably, oversampling techniques along with cross-validation were employed in our implementations to maintain data integrity and prevent data leakage. To this end, the original datasets were split into a training set and a separate holdout test set (80% for training and 20% for testing), ensuring that the test set is not used during cross-validation. Then, the tenfold cross-validation technique was utilized to split the training data into multiple folds. For each fold in the cross-validation process, the oversampling technique was only applied to the training data within that fold to ensure that oversampling is performed independently for each fold, preventing data leakage across folds. Thereafter, the model was trained on the training data within each fold and its performance was evaluated on the validation data within that fold. Finally, performance metrics for each fold were measured and then aggregated to obtain an overall assessment of the model's performance.</p>
                <p>After completing the cross-validation process, the final model was evaluated on the holdout test set that was initially set aside to provide an additional independent evaluation of our model's performance.Hyperparameters are external settings that influence an algorithm's behavior and can greatly affect the model's performance and generalization ability. Since they directly impact how well a model performs and predicts, it is important to tune these hyperparameters carefully. In our study, we made rigorous efforts to appropriately configure hyperparameters for each algorithm to optimize performance and ensure effective pattern capture.</p>
                <p>Precisely forecasting the risk of cardiovascular disease is essential for early intervention and better patient results. This paper proposed a holistic approach using the integration of machine learning and deep learning models to improve the accuracy of cardiovascular disease prediction. According to the empirical results, our combinational model presented the highest classification performance based on all evaluation metrics indicating that this combination offers a more comprehensive approach to analyzing complex cardiovascular disease data compared to using just one type of model. In order to assess the efficiency of our proposed model, it is crucial to conduct a comparison with current state-of-the-art approaches. While the majority of prior research utilized the Cleveland dataset, a component of Dataset II, for their evaluations, we opted to apply our proposed model using all specified configurations on the Cleveland dataset to ensure a fair and comprehensive comparison. An accurate comparison of the existing studies and our proposed model on the Cleveland dataset is provided in Table 9. To provide more comparison (Table 10), we also compared our proposed model with studies that concluded their experiments on Dataset I. As can be seen, our proposed model obtained the highest classification accuracy compared to the state of the arts on both datasets.</p>
                
                <p><b>Conclusion</b></p>
                <p>Cardiovascular disease is a prominent global cause of mortality, underscoring the critical need for early detection in healthcare settings. Artificial intelligence plays a crucial role in this area by pinpointing risk factors, facilitating predictive analytics, aiding decision-making, and fostering knowledge exploration. This contributes to proactive and personalized strategies for managing cardiovascular disease. Accordingly, a model which makes use of both machine learning and deep learning is proposed in this paper. The proposed model employed CNN and LSTM, as the representatives of deep learning models, besides KNN and XGB, as the representatives of machine learning models. As the output classes are defined by each classifier, majority voting is then used as an ensemble learner to predict the final output class.To demonstrate the effectiveness of the proposed model, we utilized two public datasets along with a locally collected dataset in our experiments. To ensure a valid comparison, all datasets were first processed using the same methods. The experimental results across all datasets showed that the proposed model outperformed both individual classifiers and combinations of classifiers. These findings highlight a precise model that can be utilized for predicting the risk of cardiovascular disease. Additionally, it offers an important utility for cardiologists and physicians in categorizing new patients and assessing the necessary human resources, including doctors, technicians, nurses, and vital medical equipment.</p>
                <p>There are abundant opportunities to enhance this research and address the constraints of the current study. One strategy involves broadening the study by replicating the experiment using larger real-world datasets. Future research could investigate alternative combinations of machine learning and deep learning models for predicting cardiovascular disease. Moreover, implementing novel feature selection methods could offer a more comprehensive insight into crucial features, leading to improved prediction accuracy. Exploring the application of the proposed model in other domains holds promise and could be considered as a potential avenue for future research.</p>




            </div>
        </div>
        <div class="footer">
            <p>&copy; 2025 ANFIS Heart Disease. All Rights Reserved.</p>
        </div>
    </div>
</body>
</html>
